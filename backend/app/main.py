"""
FastAPI Backend for Eye-scGPT Annotation Platform
Main application entry point
"""

from fastapi import FastAPI, File, UploadFile, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import FileResponse, JSONResponse
from fastapi.staticfiles import StaticFiles
import os
import shutil
from pathlib import Path
from typing import List
import uuid
from datetime import datetime
import logging

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Initialize FastAPI app
app = FastAPI(
    title="Eye-scGPT Annotation Platform",
    description="Automated cell type annotation using fine-tuned eye-scGPT model",
    version="1.0.0"
)

# CORS configuration
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000", "http://localhost:80"],  # Update in production
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Create directories
UPLOAD_DIR = Path("./uploads")
RESULTS_DIR = Path("./results")
UPLOAD_DIR.mkdir(exist_ok=True)
RESULTS_DIR.mkdir(exist_ok=True)

# Configuration
MAX_UPLOAD_SIZE = 5 * 1024 * 1024 * 1024  # 5GB
ALLOWED_EXTENSIONS = {".h5ad", ".h5", ".rds"}


# ==================== Utility Functions ====================

def validate_file_extension(filename: str) -> bool:
    """Validate file extension"""
    return Path(filename).suffix.lower() in ALLOWED_EXTENSIONS


def generate_job_id() -> str:
    """Generate unique job ID"""
    return f"{datetime.now().strftime('%Y%m%d_%H%M%S')}_{uuid.uuid4().hex[:8]}"


# ==================== API Endpoints ====================

@app.get("/")
async def root():
    """Health check endpoint"""
    return {
        "status": "online",
        "service": "Eye-scGPT Annotation Platform",
        "version": "1.0.0"
    }


@app.post("/api/upload")
async def upload_file(file: UploadFile = File(...)):
    """
    Upload single-cell omics data file
    Supported formats: .h5ad, .h5 (Scanpy), .rds (Seurat)
    """
    try:
        # Validate file extension
        if not validate_file_extension(file.filename):
            raise HTTPException(
                status_code=400,
                detail=f"Invalid file format. Supported formats: {', '.join(ALLOWED_EXTENSIONS)}"
            )
        
        # Generate job ID
        job_id = generate_job_id()
        
        # Create job directory
        job_dir = UPLOAD_DIR / job_id
        job_dir.mkdir(exist_ok=True)
        
        # Save uploaded file
        file_path = job_dir / file.filename
        
        # Save file in chunks to handle large files
        with open(file_path, "wb") as buffer:
            shutil.copyfileobj(file.file, buffer)
        
        file_size = file_path.stat().st_size
        
        logger.info(f"File uploaded: {file.filename}, Job ID: {job_id}, Size: {file_size} bytes")
        
        return {
            "status": "success",
            "job_id": job_id,
            "filename": file.filename,
            "file_size": file_size,
            "message": "File uploaded successfully"
        }
    
    except Exception as e:
        logger.error(f"Upload error: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Upload failed: {str(e)}")


@app.post("/api/annotate/{job_id}")
async def annotate(job_id: str):
    """
    Perform cell type annotation using eye-scGPT model
    This is a placeholder - integrate your actual model inference here
    """
    try:
        job_dir = UPLOAD_DIR / job_id
        
        if not job_dir.exists():
            raise HTTPException(status_code=404, detail="Job not found")
        
        # Get uploaded file
        files = list(job_dir.glob("*"))
        if not files:
            raise HTTPException(status_code=404, detail="No file found for this job")
        
        input_file = files[0]
        
        logger.info(f"Starting annotation for job: {job_id}")
        
        # TODO: Integrate actual scGPT model inference
        # This is a placeholder implementation
        # Replace with your actual model inference code:
        # from app.services.scgpt_service import run_annotation
        # result = run_annotation(input_file, job_id)
        
        # Placeholder response
        result_dir = RESULTS_DIR / job_id
        result_dir.mkdir(exist_ok=True)
        
        # In production, this would be generated by your model
        result_files = {
            "annotations_csv": f"{job_id}_annotations.csv",
            "annotated_h5ad": f"{job_id}_annotated.h5ad",
            "umap_plot": f"{job_id}_umap.png"
        }
        
        logger.info(f"Annotation completed for job: {job_id}")
        
        return {
            "status": "success",
            "job_id": job_id,
            "message": "Annotation completed successfully",
            "results": result_files,
            "timestamp": datetime.now().isoformat()
        }
    
    except Exception as e:
        logger.error(f"Annotation error for job {job_id}: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Annotation failed: {str(e)}")


@app.get("/api/status/{job_id}")
async def get_status(job_id: str):
    """Get job status"""
    try:
        job_dir = UPLOAD_DIR / job_id
        result_dir = RESULTS_DIR / job_id
        
        if not job_dir.exists():
            raise HTTPException(status_code=404, detail="Job not found")
        
        status = "uploaded"
        if result_dir.exists():
            status = "completed"
        
        return {
            "job_id": job_id,
            "status": status,
            "has_results": result_dir.exists()
        }
    
    except Exception as e:
        logger.error(f"Status check error: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/download/{job_id}/{filename}")
async def download_result(job_id: str, filename: str):
    """Download annotation results"""
    try:
        result_dir = RESULTS_DIR / job_id
        file_path = result_dir / filename
        
        if not file_path.exists():
            raise HTTPException(status_code=404, detail="File not found")
        
        logger.info(f"Downloading: {filename} for job: {job_id}")
        
        return FileResponse(
            path=file_path,
            filename=filename,
            media_type="application/octet-stream"
        )
    
    except Exception as e:
        logger.error(f"Download error: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Download failed: {str(e)}")


@app.get("/api/results/{job_id}")
async def list_results(job_id: str):
    """List all available results for a job"""
    try:
        result_dir = RESULTS_DIR / job_id
        
        if not result_dir.exists():
            return {
                "job_id": job_id,
                "status": "no_results",
                "files": []
            }
        
        files = []
        for file_path in result_dir.iterdir():
            if file_path.is_file():
                files.append({
                    "filename": file_path.name,
                    "size": file_path.stat().st_size,
                    "download_url": f"/api/download/{job_id}/{file_path.name}"
                })
        
        return {
            "job_id": job_id,
            "status": "completed",
            "files": files
        }
    
    except Exception as e:
        logger.error(f"List results error: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


@app.delete("/api/cleanup/{job_id}")
async def cleanup_job(job_id: str):
    """Clean up uploaded and result files for a job"""
    try:
        job_dir = UPLOAD_DIR / job_id
        result_dir = RESULTS_DIR / job_id
        
        deleted = False
        
        if job_dir.exists():
            shutil.rmtree(job_dir)
            deleted = True
            
        if result_dir.exists():
            shutil.rmtree(result_dir)
            deleted = True
        
        if not deleted:
            raise HTTPException(status_code=404, detail="Job not found")
        
        logger.info(f"Cleaned up job: {job_id}")
        
        return {
            "status": "success",
            "message": f"Job {job_id} cleaned up successfully"
        }
    
    except Exception as e:
        logger.error(f"Cleanup error: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)